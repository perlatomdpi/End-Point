{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-Define-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCwcTD+I6uLL099kTBwFxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perlatomdpi/End-Point/blob/main/1_Define_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWxgHKpnBFA"
      },
      "source": [
        "# **Define the Machine Learning model**\n",
        "We ceeate a model able to predict the miles per gallon of different car models based on specific feature of the cars. <br>\n",
        "We'll use transfomr this model with Flask to be used as an End-Point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AepyN4mAmpDY"
      },
      "source": [
        "from werkzeug.wrappers import Request, Response\n",
        "from flask import Flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgUpbm8Qnmin"
      },
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")              # display hello world in the web page\n",
        "def hello():\n",
        "    return \"hello world\"\n",
        "\n",
        "if __name__==\"__main__\":     # run the application\n",
        "    from werkzeug.serving import run_simple\n",
        "    run_simple('localhost', 9000, app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNu3SYuTnnRz"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping       # it is the optioin to stop the training process if the NN is not getting any better\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVs1U3PIr0aS"
      },
      "source": [
        "### **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa3mU4p8nnIC"
      },
      "source": [
        "df = pd.read_csv(r'C:\\Users\\..\\auto.mpg.cvs', na_values=['NA','?'])       # convert na\n",
        "df.isnull().sum()                                                         # check null values\n",
        "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())  # fill nulls with median\n",
        "\n",
        "x = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']]   # define the independent variables\n",
        "y = df['mpg'].values                                                                              # convert the dependent variable to a numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF2yTSnSv61U"
      },
      "source": [
        "### **Split the data into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVmKA6L2sj2v"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12INZThYwfjf"
      },
      "source": [
        "### **Define the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9sfXuHOwmPX"
      },
      "source": [
        "model = Sequential()\n",
        "# define first layer in the Neural network\n",
        "model.add(Dense(25, input_dim=x.shape[1], # 25 neurons inside the first layer with in input 7 variables --> x.shape[1] --> (cylinders, etc.)\n",
        "                    activation='relu'))   # define relu as activation function\n",
        "\n",
        "# define a second hidden layer\n",
        "model.add(Dense(10, activation='relu'))   # here is not necessary to define the input dimension --> is neeed only in the input layer\n",
        "\n",
        "# define output layer\n",
        "model.add(Dense(1))    # we define only 1 output --> mpg\n",
        "                                          \n",
        "# compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')    # use msr as loss function, use adaptive momentum to do gradient descent optimization\n",
        "\n",
        "\n",
        "# define monitor:\n",
        "# monitor the validation loss and \n",
        "# min_delta is an hyper-parameter --> is is the minimum \n",
        "# addition which we want the model to archive during training\n",
        "# if min_delta=2e-3 is not reached --> stopp the leaning process\n",
        "# patience=5 --> give the allowance to train 5 times \n",
        "# if after 5 time we not archive min_delta=1e-3 --> stop the process\n",
        "# restore_best_weights=True --> if we not reachmin_delta=1e-3 --< resture the best archivment\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True) $\n",
        "\n",
        "\n",
        "# traini the model\n",
        "mode.fit(x_train, y=train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=1000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5aW08I53Qw3"
      },
      "source": [
        "# **Evaluating and saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnsQFeyA3V70"
      },
      "source": [
        "prediction = model.predict(x_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(prediction, y_test))\n",
        "print(f'the mean squared error between prediction and real mpg (y_test) is: {score}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZlYYEpQmdwL"
      },
      "source": [
        "# **Save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6yTdNm3mgrb"
      },
      "source": [
        "os.chdir(r'C:\\User...\\Deploy')   # point to a specific folder\n",
        "model.save(os.oath.join(os.getcwd()), \"mpg_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}